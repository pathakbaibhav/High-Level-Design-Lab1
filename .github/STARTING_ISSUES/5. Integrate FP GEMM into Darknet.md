## 1. Basic Integration 

To prepare integrating GEMM back into your Darknet code, create a branch `gemm_fp_cpu` in the darknet repository. Switch to this branch. 

Copy the fucntions for  fixed-point GEMM back into the Darknet code (file ```darknet/src/gemm.c```). Modify the gemm function to use your fixed point version instead of original floating point version. 

Note: This lab is taking a shortcut to simplify the assignment. A better approach would be to isolate gemm_fp_cpu function into a separate file to use it both for the testbench as well as for the darknet integration. 

## 2. Accuracy Comparison

To measure accuracy of object detection applications, a commonly used quality loss metric is the so-called mean Average Precision (mAP), which is essentially the average of the maximum precisions at different recall values. For further theoretical background, refer to this [link](https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173). Darknet includes the capability to compute the mAP of your modified program as follows:

1) Put the (relative) paths of the images you want to be included in the mAP computation into a coco_testdev file in the darknet directory. For example:

    ```
    echo "data/dog.jpg" > coco_testdev
    ```

2) Make sure that the ground truth reference files (e.g. data/dog.txt) are the ones produced by a run of the original, unmodified floating-point Darknet implementation. Then, run your modified fixed-point implementation on the images listed in the coco_testdev file and compute the mAP:

    ```
    ./darknet detector map cfg/coco.data cfg/yolov3-tiny.cfg yolov3-tiny.weights
    ```

Prior results indicate that an mAP of 100 is possible with int32 fixed point data processing. 


## 3. Performance Optimization 

Explore opportunities for further optimizations in the larger Darknet context. 

Some hints for possible avenues:

- So far, we have performed the floating- to fixed-point at the GEMM boundary. This will require conversion overhead on every GEMM call. To gain more significant system-wide performance, you can explore pushing the conversion boundary further beyond the GEMM.

- Hint: When and where is the first time in the code that we operate with floating-point images or weights? Instead of converting to fixed-point not until the GEMM is called, can we convert them the values earlier, e.g. the first time we see them? 

- More specifically, many of the weight values used in the GEMM are constant. Can we convert the weights into fixed-point constants at compile time (rather than doing run-time conversion)?

- Some pre-processing operations before the GEMM in the convolutional layers are filling the matrix C with zeros. The larger the size of matrix C, the longer run-time it takes to complete. Can we do something smarter? Do we have to always fill with zeros?

- Explore the fixed-point data types design space. What is the smallest fixed-point data type that you can use during conversion? In general, the smaller data type the better in terms of performance. In particular, you can exploit more SIMD parallelism (data packing) with smaller data types (see below).

Use profiling to measure and guide you towards achieving as much improvement in total Darknet runtime as you can, with as minimal a loss in the detection accuracy of the overall YOLO application that includes your converted fixed-point modules and interfaces. Note that as you are optimizing the entire Darknet software, as discussed above a certain amount of prediction accuracy loss is expected. That being said, your optimized version should be able to at least predict that there are four objects in the picture: dog, bicycle, car, truck. Your program should at least predict these four objects. The prediction accuracy of these four objects might vary, but the accuracy vs. performance tradeoff should be optimized.


### 3.1 Developing and Testing the Optimization 

Develop and functionally validate your code on the x86 development host. 

Once functionaly is validated, use the your [Jenkins](https://neu-ece-7368-f22.github.io/Jenkins.html) build server to execute on the ZedBoard for accurate timing / profiling information.

If your code is ARM specific and you want to validate before submitting to the build server, you can use the [Home Environment](https://neu-ece-7368-f22.github.io/EnvironmentHome.html), or the [COE Environment](https://neu-ece-7368-f22.github.io/COEEnvironment.html). Both include a simulator for our ZedBoard based on QEMU.

## 4. Preport

Report the following:

- Total execution time of Darknet using your optimized fixed-point versus the original floating-point implementation.

- mAP of Darknet using your optimized fixed-point version as compared against the original floating-point detection results. 
